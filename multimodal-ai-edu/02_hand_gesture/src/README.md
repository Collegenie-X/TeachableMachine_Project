# 손동작 인식 시스템

이 애플리케이션은 Teachable Machine 모델을 사용하여 두 가지 다른 애플리케이션에서 손동작을 인식합니다:
1. 가위바위보 게임
2. 수어 번역기

## 파일 구조 및 설명

프로젝트는 유지보수와 확장이 쉽도록 모듈화된 구조로 설계되었습니다:

```
src/
├── main.py                 # 메인 진입점 (애플리케이션 실행)
├── rock_paper_scissors.py  # 가위바위보 게임 구현
├── sign_language.py        # 수어 번역기 구현
├── game_control.py         # 레거시 코드 (사용되지 않음)
├── utils/                  # 유틸리티 함수 패키지
│   ├── __init__.py         # 패키지 초기화 파일
│   ├── image_processing.py # 이미지 처리 유틸리티
│   └── model_utils.py      # 모델 로딩 및 예측 유틸리티
└── README.md               # 현재 읽고 계신 파일
```

### 모듈 설명

1. **main.py**: 애플리케이션의 진입점으로, 명령줄 인자를 파싱하고 선택된 모드에 따라 적절한 애플리케이션을 실행합니다.

2. **rock_paper_scissors.py**: 가위바위보 게임 구현체입니다. 주요 기능:
   - 실시간 손동작 인식을 통한 가위바위보 게임
   - 3초 타이머 내에 안정적인 손동작 인식
   - 타임아웃 시 자동 패배 처리
   - 결과 화면 중앙에 큰 글씨로 표시
   - 점수 추적 및 표시

3. **sign_language.py**: 수어 번역기 구현체입니다. 주요 기능:
   - 실시간 수어 동작 인식 및 표시
   - 도전 과제 모드로 수어 학습 게임화
   - 성공 시 남은 시간에 비례한 점수 획득
   - 성공/실패 결과 화면 중앙에 표시
   - 학습 진행 상황 추적

4. **utils/image_processing.py**: 이미지 처리 관련 유틸리티 함수를 제공합니다:
   - `preprocess_image()`: 모델 예측을 위한 이미지 전처리
   - `put_text_with_background()`: 반투명 배경이 있는 텍스트 표시
   - `center_text()`: 화면 중앙에 텍스트 위치 계산
   - `create_transparent_overlay()`: 반투명 오버레이 생성

5. **utils/model_utils.py**: 모델 관련 유틸리티 함수를 제공합니다:
   - `patch_depthwise_conv()`: TensorFlow 모델 호환성 패치
   - `clean_label()`: Teachable Machine 라벨 정리
   - `load_model_and_labels()`: 모델 및 라벨 파일 로딩
   - `get_prediction()`: 이미지로부터 모델 예측 획득

## 필요 조건

### 필수 패키지
```bash
pip install opencv-python tensorflow numpy
```

### Teachable Machine 모델 준비
1. [Teachable Machine](https://teachablemachine.withgoogle.com/)에서 이미지 프로젝트 생성
2. 가위바위보 게임: 가위, 바위, 보 손동작 이미지로 학습
3. 수어 번역기: 다양한 수어 동작 이미지로 학습
4. 모델 내보내기: "Export Model" > "TensorFlow" > "Keras" 다운로드
5. 다운로드한 zip 파일 압축 해제

## 모델 파일 구조
모델 파일을 다음 구조로 저장하세요:
```
models/
├── rps_model/             # 가위바위보 모델
│   ├── keras_model.h5
│   └── labels.txt
└── sign_model/            # 수어 번역 모델
    ├── keras_model.h5
    └── labels.txt
```

## 애플리케이션 실행

### 가위바위보 게임
```bash
cd src
python main.py --mode rps --model ../models/rps_model/keras_model.h5 --labels ../models/rps_model/labels.txt
```

### 수어 번역기
```bash
cd src
python main.py --mode sign --model ../models/sign_model/keras_model.h5 --labels ../models/sign_model/labels.txt
```

### 명령줄 옵션
```
--mode: 애플리케이션 모드 (rps 또는 sign)
--model: 모델 파일 경로
--labels: 라벨 파일 경로
--camera: 카메라 장치 번호 (기본값: 0)
--image_size: 입력 이미지 크기 (기본값: 224)
```

## 사용 방법

### 가위바위보 게임
1. 프로그램 실행 후 스페이스바를 눌러 게임 시작
2. 3초 타이머 내에 가위, 바위, 보 중 하나의 손동작을 취하고 유지
3. 안정적으로 인식되면 즉시 결과 표시
4. 타임아웃 시 자동 패배 처리
5. 결과 화면에서 스페이스바를 눌러 다시 게임 시작
6. ESC 키를 눌러 종료

### 수어 번역기
1. 다양한 수어 동작을 카메라에 보여줍니다
2. 동작을 안정적으로 유지하면 인식됩니다
3. 'c'를 눌러 도전 과제 시작 - 5초 내에 요청된 수어를 표현해야 함
4. 성공 시 남은 시간에 비례하여 점수 획득 (최대 40점)
5. ESC 키를 눌러 종료

## 주요 핵심 기능

1. **모듈화된 설계**
   - 기능별 독립적인 모듈로 분리하여 유지보수 용이
   - 유틸리티 기능을 공통 패키지로 분리하여 코드 재사용성 향상
   - 각 기능에 대한 자세한 문서화로 코드 이해도 향상

2. **손동작 안정화 알고리즘**
   - 연속된 프레임에서 같은 손동작이 감지되었을 때만 인식
   - 안정성 카운터를 통해 오탐지 방지 및 사용자 경험 향상
   - 안정성 임계값 조정 가능 (기본값: 8프레임)

3. **시간 제한 기반 게임 방식**
   - 가위바위보: 3초 내에 안정적인 손동작 인식
   - 수어 번역기: 5초 내에 요청된 수어 표현
   - 시간에 따른 색상 변화로 직관적인 피드백 제공

4. **시각적 피드백 개선**
   - 반투명 배경으로 텍스트 가독성 향상
   - 결과를 화면 중앙에 큰 글씨로 표시
   - 색상 코드를 통한 직관적인 상태 표시 (녹색: 성공, 빨간색: 실패)

5. **TensorFlow 호환성 패치**
   - Teachable Machine 모델과 TensorFlow 간의 호환성 문제 자동 해결
   - 'groups' 파라미터 충돌 자동 해결

6. **텍스트 중앙 정렬 유틸리티**
   - 화면 크기에 관계없이 텍스트를 중앙에 정렬
   - 다양한 폰트 크기와 두께 지원

7. **수어 학습 도전 모드**
   - 랜덤 수어 도전 과제 생성
   - 시간 기반 점수 시스템으로 학습 동기부여
   - 진행 상황 추적 및 피드백 제공

## 교육적 활용

이 시스템은 교육 현장에서 다음과 같이 활용할 수 있습니다:
1. 손동작 인식 개념 교육
2. 머신러닝 응용 프로그램 시연
3. 컴퓨터 비전 기반 인터랙티브 게임 개발
4. 수어 번역 기술 학습
5. 파이썬 모듈화 프로그래밍 교육

## 문제 해결

### 카메라 문제
- 카메라가 다른 애플리케이션에서 사용 중이 아닌지 확인
- 카메라 장치 번호가 올바른지 확인 (다른 번호 시도)
- 카메라 드라이버가 제대로 설치되었는지 확인

### 모델 정확도 문제
- 각 동작에 충분한 학습 데이터 확보
- 다양한 조명 조건과 배경에서 학습
- 손동작이 카메라 프레임 내에 잘 보이도록 유지

### 패키지 설치 문제
- 필요한 패키지가 모두 설치되었는지 확인
  ```bash
  pip install opencv-python tensorflow numpy
  ```
- 호환성 문제 발생 시 버전 지정 설치
  ```bash
  pip install tensorflow==2.10.0
  ```
